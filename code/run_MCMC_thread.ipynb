{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some imports\n",
    "import sys\n",
    "import os\n",
    "import MCMC_Noddy as mcmc\n",
    "import GA_Noddy as GA\n",
    "import PSO_basic as PSO\n",
    "import NSGA_Noddy as NSGA\n",
    "from glob import glob\n",
    "import vedo as vtkP\n",
    "\n",
    "# give correct permissions to the executable\n",
    "folder = os.getcwd()\n",
    "noddyEXE = folder+'/noddy_linux.exe'\n",
    "strV = 'chmod 777 '+noddyEXE\n",
    "os.system(strV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Choose hyper parameters (don't be frightened - you can just run this and keep them all at default!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HyperParameters = {}\n",
    "\n",
    "# what optimisation method are you using?\n",
    "# choose from ['MCMC', 'GA', 'NSGA', 'Annealing']\n",
    "HyperParameters['OptimMethod']='MCMC'\n",
    "\n",
    "# The number of faults in the model ::: (integer) ::: If less than 6, then it's a pre configured scenario\n",
    "HyperParameters['ScenarioNum'] = 18\n",
    "\n",
    "# how to shift the geophysical data to be similar to simulation values ['Median Datum Shift', 'Median Const Datum Shift']\n",
    "HyperParameters['SimulationShiftType'] = 'Median Datum Shift'\n",
    "\n",
    "# how to normalize each data type before combining them ::: ['MedianInitialRounds', 'Given']\n",
    "HyperParameters['DatNormMethod'] = 'MedianInitialRounds'\n",
    "# you can also preconfigure what is the beginning error level for each datatype as follows. \n",
    "# this is used only if provided \"given\" in above option\n",
    "HyperParameters['DatNormCoef'] = {'Grav': 2.4, 'Tracer': 1.0, \n",
    "                        'FaultMarkers': 500, 'GT': 315, 'Mag':300}\n",
    "\n",
    "# In the MCMC and annealing method. Whether to have a multiplier on the \n",
    "# stepping size based on the error level. step = (Multiplier)*(error btwn 0-1)*perturbation \n",
    "# ::: ['LinearErrorBased', 'None']\n",
    "HyperParameters['ExplorationRate'] = 'LinearErrorBased'\n",
    "HyperParameters['SteppingSizeMult'] = 1/0.9\n",
    "\n",
    "# Is the error calculated based on mismatch for all observed data from the whole model [Global], \n",
    "# or only data points that are local/around the location of the parameter/fault [Local]. \n",
    "HyperParameters['ErrorType'] = 'Global'\n",
    "\n",
    "# If you choose \"Local\", then how often should you update what ares\n",
    "# is considered local for every parameter (update once or many times)? :::['Once', 'Many']\n",
    "HyperParameters['parameters']= 'Many'\n",
    "# The local radius is calculated by taking the fault length, and this radius can be multiplied by a value. ::: [1, 2.5]\n",
    "HyperParameters['localWeightRadiusMult']= 1.5\n",
    "# after how many rounds update the area designated as local? and every how many rounds recalculate?\n",
    "HyperParameters['StartUpdateLocalWeight']= 45\n",
    "HyperParameters['localWeightRadiusMult']= 35\n",
    "\n",
    "# The norm used for the optimisation ::: ['L1', 'L2', 'Lhalf']\n",
    "HyperParameters['ErrorNorm'] = 'L1'\n",
    "\n",
    "# For MCMC and annealing, should you set the initial rounds as exploratory, without any optimisation/search/update\n",
    "HyperParameters['ExplorationStage'] = 'Explore'\n",
    "# The number of exploration rounds ::: integer\n",
    "HyperParameters['nExploreRuns'] = 50\n",
    "\n",
    "# What is the normalization constant in the MCMC (std of the error)? \n",
    "# It can be set to achieve a certain acceptance rate, for example.\n",
    "#::: ['Track Acceptance', 'Error must decrease', 'Const diff']\n",
    "HyperParameters['AcceptProbType'] = 'Track Acceptance'\n",
    "# If you want to have a target acceptance, that what is the goal? ::: range(0,1)\n",
    "HyperParameters['AcceptanceGoal'] = 0.2\n",
    "# If you want a constant number, set it here\n",
    "HyperParameters['ConstNormFactor'] = 0.01\n",
    "\n",
    "# cube size for the model\n",
    "HyperParameters['cubesize'] = 150\n",
    "\n",
    "# What is the largest amount the faults can move from their original placed location\n",
    "HyperParameters['GlobalMoveEachDir'] = 500\n",
    "# What is the std of the step size for this movement?\n",
    "HyperParameters['XYZ_Axes_StepStd'] = 100\n",
    "# Std for the step size of the fault dip\n",
    "HyperParameters['Dip_StepStd'] = 5\n",
    "# Std for the step size of the fault slip\n",
    "HyperParameters['Slip_StepStd'] = 50\n",
    "# Std for the step size of the fault dip direction\n",
    "HyperParameters['DipDirection_StepStd'] = 6\n",
    "# The ratio between fault length to fault slip\n",
    "HyperParameters['SlipParam'] = 0.1\n",
    "\n",
    "# Maximum range of the stratigraphy rotation\n",
    "HyperParameters['AzimuthMoveEachDirection'] = 6\n",
    "# Maximum change in dip\n",
    "HyperParameters['DipMoveEachDirection'] = 32\n",
    "# Maximum shrinking/expanding of fault amplitude\n",
    "HyperParameters['AmplitudeRatioChange'] = 0.1\n",
    "\n",
    "HyperParameters['AxisRatioChange'] = 0.1\n",
    "\n",
    "# The maximum misfit error per fault marker (otherwise can be inf)\n",
    "HyperParameters['MaxFaultMarkerError'] = 525\n",
    "\n",
    "HyperParameters['MO_WeightingMethod'] = 'Proportions'\n",
    "HyperParameters['MCMC_SwitchWeightFreq'] = 20\n",
    "\n",
    "Thread_num = 0 \n",
    "HyperParameters['thread_num'] = Thread_num        \n",
    "# don't do the toy run\n",
    "HyperParameters['Toy']=False\n",
    "\n",
    "# do you want some extra output\n",
    "HyperParameters['verbose']=True\n",
    "\n",
    "# where to output results\n",
    "HyperParameters['BaseFolder']='Combo_Scratch'\n",
    "\n",
    "HyperParameters['DataTypes'] = ['Grav', 'Mag', 'GT', 'FaultMarkers','Tracer']\n",
    "\n",
    "# origin of the model\n",
    "HyperParameters['xy_origin']=[316448, 4379166, -2700]\n",
    "\n",
    "# extent of the model\n",
    "HyperParameters['xy_extent'] = [8850, 9000,3900]\n",
    "\n",
    "HyperParameters['verbose']=True    \n",
    "\n",
    "# index of the granite layer\n",
    "HyperParameters['graniteIdx'] = 4\n",
    "\n",
    "# is this a Windows computer? (you are probably running this using binder on the server, which is linux)\n",
    "HyperParameters['Windows'] = False\n",
    "\n",
    "# are you running this from a jupyter notebook? or your terminal\n",
    "HyperParameters['jupyter'] = True\n",
    "\n",
    "# Annealing\n",
    "HyperParameters['AcceptProbType'] = 'Annealing'\n",
    "\n",
    "# Annealing: what is the initial temperature? ::: [0.001, 0.025]\n",
    "HyperParameters['InitialTemperature'] = 0.01\n",
    "# Annealing: what is the ReductionRate? ::: [0.95, 0.999]\n",
    "HyperParameters['ReductionRate'] = 0.965\n",
    "\n",
    "# how much weight to give to each data type? (multi objective)\n",
    "# equal? randomly set the proportions? all weight to single data type, but switch around every few rounds?\n",
    "# ::: ['Proportions', 'Extreme', 'Equal']\n",
    "HyperParameters['MO_WeightingMethod'] = 'Equal'\n",
    "# if \"extreme\", every how many rounds switch the weights? ::: integer\n",
    "HyperParameters['MO_SwitchWeightFreq'] = 2\n",
    "# rounds are shorter for MCMC, so can have more rounds before switching\n",
    "HyperParameters['MCMC_SwitchWeightFreq'] = 20\n",
    "\n",
    "# Genetic algorithms parameters (incl. NSGA)\n",
    "# #########################################\n",
    "\n",
    "# number of individuals/models in the population ::: [25, 80]\n",
    "HyperParameters['npop'] = 50\n",
    "    \n",
    "# what is the selection method? ::: ['selTournament', 'selStochasticUniversalSampling', 'selRoulette']\n",
    "HyperParameters['SelectionMethod'] = 'selTournament'\n",
    "# what is the tournament size? ::: [4,12]\n",
    "HyperParameters['TournamentSize'] = 7\n",
    "\n",
    "# what is the mating method? ::: ['cxTwoPoint','cxOnePoint','cxUniform']\n",
    "HyperParameters['MatingMethodGlobal'] = 'cxTwoPoint'\n",
    "\n",
    "# what is the mating method for a local formulation? ::: ['cxOnePointLocal','cxTwoPointLocal', 'cxLocalErrorPropExchange']\n",
    "HyperParameters['MatingMethodLocal'] = 'cxLocalErrorPropExchange'\n",
    "\n",
    "# parameter used in the mating algorithms ::: [0.6, 1] \n",
    "HyperParameters['MatingSwapRange'] = 0.7\n",
    "\n",
    "# parameter used in the mating algorithm cxUniform ::: [0.3, 0.7]\n",
    "HyperParameters['MatingSwapProb'] = 0.5\n",
    "\n",
    "# What is the mating probability ::: [0.6, 1] or [0-1] in general\n",
    "HyperParameters['IndMatingProb'] = 0.8\n",
    "\n",
    "# what is the mutating method? ::: ['mutPolynomialBounded', 'mutGaussian', 'mutUniformFloat']\n",
    "HyperParameters['MutatingMethod'] = 'mutGaussian'\n",
    "\n",
    "# parameter used in the algorithm mutPolynomialBounded ::: [80, 120]\n",
    "HyperParameters['Eta'] = 100\n",
    "\n",
    "# What is the individual mutating probability ::: [0.2, 0.4] or [0-1] in general\n",
    "HyperParameters['IndMutatingProb'] = 0.3\n",
    "HyperParameters['PbMutateParameter'] = 0.2\n",
    "\n",
    "HyperParameters['LocalWeightsMode'] = 'na'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Run and view results every x times (x=output image frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HyperParameters['nruns']=200\n",
    "HyperParameters['OutputImageFreq'] = 15        \n",
    "\n",
    "if(HyperParameters['OptimMethod']=='MCMC'):\n",
    "    mcmc.MCMC_Noddy(HyperParameters)        \n",
    "elif(HyperParameters['OptimMethod']=='GA'):\n",
    "    GA.GA_Noddy(HyperParameters)            \n",
    "elif(HyperParameters['OptimMethod']=='Annealing'):\n",
    "    mcmc.MCMC_Noddy(HyperParameters)                    \n",
    "elif(HyperParameters['OptimMethod']=='NSGA'):\n",
    "    NSGA.NSGA2_Noddy(HyperParameters)                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Find the model with least error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through all of the files and take the best and and another 5 random ones and copy them over\n",
    "def GetIterationNumFromFile(file):\n",
    "    result = re.search('G_(.*)_Err', file)\n",
    "    return int(result.group(1))\n",
    "\n",
    "def GetErrFromFile(file):\n",
    "    result = re.search('Err_(.*).his', file)\n",
    "    return float(result.group(1))\n",
    "\n",
    "folder = os.getcwd()+'/Combo_Scratch/Thread'+str(Thread_num)+'/HistoryFileInspection/'\n",
    "files = glob(folder+'*.his')\n",
    "nFiles = len(files)\n",
    "\n",
    "MasterFileList = []\n",
    "ErrV=1000000.0\n",
    "bestIter=0\n",
    "for i in range(nFiles):\n",
    "    file_i = files[i]\n",
    "    print('reading: '+ file_i)\n",
    "    Err=GetErrFromFile(file_i)\n",
    "    Iter=GetIterationNumFromFile(file_i)\n",
    "    if(Err<ErrV):\n",
    "        ErrV = Err\n",
    "        bestIter = Iter\n",
    "        best_model_file = file_i\n",
    "\n",
    "print('best file is: ' + best_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Plot in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot3d_util as plt3d\n",
    "import vedo as vtkP\n",
    "import pandas as pd\n",
    "from scipy.spatial import Delaunay\n",
    "vtkP.settings.embedWindow('k3d') #you can also choose to change to itkwidgets, k3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation time took 5.0256569385528564 seconds\n",
      "Parsing time took 6.906073331832886 seconds\n",
      "The number of triangle elements (cells/faces) is: 200305\n",
      "Convert 2 VTK time took 0.594963550567627 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f54894b280e4229b758d28de5a1d6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Plot(antialias=3, axes=['x', 'y', 'z'], axes_helper=1.0, background_color=16777215, camera=[327825.97439773346â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Alter the mesh size if desiring to speed up the process. Recommended size is 100\n",
    "output_name = 'noddy_out'\n",
    "cubesize = 100\n",
    "includeGravityCalc = 0\n",
    "xy_origin=[316448, 4379166, -2700]\n",
    "\n",
    "plot = vtkP.Plotter(axes=1, bg='white', interactive=1)\n",
    "plt3d.plot_3d_model(best_model_file, cubesize, plot, xy_origin=[316448, 4379166, -2700])\n",
    "\n",
    "# add topography\n",
    "##################\n",
    "# perform a 2D Delaunay triangulation to get the cells from the point cloud\n",
    "landSurfacePD = pd.read_csv(\"Data/TopographyNew2.csv\")\n",
    "landSurfacePD = landSurfacePD[['X', 'Y', 'rvalue_1']].values\n",
    "tri = Delaunay(landSurfacePD[:, 0:2])\n",
    "\n",
    "# create a mesh object for the land surface\n",
    "landSurface = vtkP.Mesh([landSurfacePD, tri.simplices])\n",
    "\n",
    "# in order to color it by the elevation, we use the z values of the mesh\n",
    "zvals = landSurface.points()[:, 2]\n",
    "landSurface.pointColors(zvals, cmap=\"terrain\", vmin=1000)\n",
    "landSurface.name = \"Land Surface\" # give the object a name\n",
    "\n",
    "plot+=landSurface\n",
    "\n",
    "plot.show(viewup='z')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
